{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìö Workshop: RAG + LangChain + Streamlit\n",
        "\n",
        "## ‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà 5: Wrap-up & Advanced Topics (3:30 ‚Äì 4:00)\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
        "- Recap pipeline: Load ‚Üí Split ‚Üí Embed ‚Üí Store ‚Üí Retrieve ‚Üí LLM\n",
        "- ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç (context, latency, token cost)\n",
        "- ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Qdrant / Pinecone ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö production\n",
        "- ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° Features: Upload PDF, Multi-documents, Source citations\n",
        "- ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢: ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏õ‡∏£‡∏±‡∏ö UI ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Recap: RAG Pipeline\n",
        "\n",
        "### Pipeline ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô:\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    A[PDF Documents] --> B[Document Loader]\n",
        "    B --> C[Text Splitter]\n",
        "    C --> D[Embeddings]\n",
        "    D --> E[Vector Store]\n",
        "    \n",
        "    F[User Question] --> G[Embeddings]\n",
        "    G --> H[Vector Search]\n",
        "    E --> H\n",
        "    H --> I[Retriever]\n",
        "    I --> J[Context Documents]\n",
        "    J --> K[Prompt Template]\n",
        "    K --> L[LLM]\n",
        "    L --> M[Answer]\n",
        "```\n",
        "\n",
        "### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:\n",
        "\n",
        "1. **üìÑ Document Loading** - ‡πÇ‡∏´‡∏•‡∏î PDF ‡∏î‡πâ‡∏ß‡∏¢ PyPDFLoader\n",
        "2. **‚úÇÔ∏è Text Splitting** - ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ RecursiveCharacterTextSplitter\n",
        "3. **üî¢ Embeddings** - ‡∏™‡∏£‡πâ‡∏≤‡∏á vectors ‡∏î‡πâ‡∏ß‡∏¢ HuggingFaceEmbeddings\n",
        "4. **üóÑÔ∏è Vector Store** - ‡πÄ‡∏Å‡πá‡∏ö vectors ‡πÉ‡∏ô FAISS\n",
        "5. **üîç Retrieval** - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\n",
        "6. **ü§ñ LLM** - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ Groq Llama\n",
        "7. **üé® UI** - ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢ Streamlit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç\n",
        "\n",
        "### 1. **Context Window Limit**\n",
        "\n",
        "**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** LLM ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß\n",
        "\n",
        "**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**\n",
        "- ‡πÉ‡∏ä‡πâ Text Splitter ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô chunks ‡πÄ‡∏•‡πá‡∏Å‡πÜ\n",
        "- ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ `chunk_size` ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\n",
        "- ‡πÉ‡∏ä‡πâ `chunk_overlap` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢\n",
        "\n",
        "```python\n",
        "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î chunk\n",
        "    chunk_overlap=200  # ‡πÄ‡∏û‡∏¥‡πà‡∏° overlap\n",
        ")\n",
        "```\n",
        "\n",
        "### 2. **Latency (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏ä‡πâ‡∏≤)**\n",
        "\n",
        "**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ä‡πâ‡∏≤\n",
        "\n",
        "**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**\n",
        "- ‡πÉ‡∏ä‡πâ Vector Store ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß (FAISS)\n",
        "- ‡∏•‡∏î‡∏Ñ‡πà‡∏≤ `k` (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤)\n",
        "- ‡πÉ‡∏ä‡πâ LLM ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß (Groq)\n",
        "- Cache embeddings ‡πÅ‡∏•‡∏∞ vector store\n",
        "\n",
        "### 3. **Token Cost**\n",
        "\n",
        "**‡∏õ‡∏±‡∏ç‡∏´‡∏≤:** ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏™‡∏π‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ LLM API\n",
        "\n",
        "**‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:**\n",
        "- ‡πÉ‡∏ä‡πâ LLM ‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ñ‡∏π‡∏Å (Groq)\n",
        "- ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î context ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÑ‡∏õ\n",
        "- ‡πÉ‡∏ä‡πâ local embeddings (HuggingFace)\n",
        "- Optimize prompt template\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè≠ Production Vector Stores\n",
        "\n",
        "### ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Vector Stores:\n",
        "\n",
        "| Vector Store | Pros | Cons | Use Case |\n",
        "|--------------|------|------|----------|\n",
        "| **FAISS** | ‡πÄ‡∏£‡πá‡∏ß, ‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡πâ‡∏≠‡∏¢ | ‡πÑ‡∏°‡πà persistent, ‡πÑ‡∏°‡πà‡∏°‡∏µ API | Development, Demo |\n",
        "| **Qdrant** | Persistent, API, Metadata filtering | ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á server | Production |\n",
        "| **Pinecone** | Managed service, Scalable | ‡πÄ‡∏™‡∏µ‡∏¢‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢ | Enterprise |\n",
        "| **Chroma** | ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô, Persistent | Performance ‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÄ‡∏ó‡πà‡∏≤ | Small projects |\n",
        "\n",
        "### Qdrant ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Production:\n",
        "\n",
        "```python\n",
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Qdrant\n",
        "pip install qdrant-client\n",
        "\n",
        "# ‡∏£‡∏±‡∏ô Qdrant server\n",
        "docker run -p 6333:6333 qdrant/qdrant\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ Qdrant ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î\n",
        "from langchain_community.vectorstores import Qdrant\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    collection_name=\"documents\",\n",
        "    url=\"http://localhost:6333\"\n",
        ")\n",
        "```\n",
        "\n",
        "### Pinecone ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Enterprise:\n",
        "\n",
        "```python\n",
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Pinecone\n",
        "pip install pinecone-client\n",
        "\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Pinecone\n",
        "import pinecone\n",
        "pinecone.init(api_key=\"your-api-key\", environment=\"your-environment\")\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ Pinecone\n",
        "from langchain_community.vectorstores import Pinecone\n",
        "\n",
        "vectorstore = Pinecone.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=embeddings,\n",
        "    index_name=\"documents\"\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Advanced Features\n",
        "\n",
        "### 1. **Upload PDF ‡πÅ‡∏ö‡∏ö Real-time**\n",
        "\n",
        "```python\n",
        "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô Streamlit\n",
        "uploaded_file = st.file_uploader(\"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î PDF\", type=\"pdf\")\n",
        "\n",
        "if uploaded_file:\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp_file:\n",
        "        tmp_file.write(uploaded_file.getvalue())\n",
        "        tmp_file_path = tmp_file.name\n",
        "    \n",
        "    # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• PDF\n",
        "    loader = PyPDFLoader(tmp_file_path)\n",
        "    documents = loader.load()\n",
        "    \n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á vector store ‡πÉ‡∏´‡∏°‡πà\n",
        "    new_vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "    \n",
        "    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï RAG service\n",
        "    rag_service.vectorstore = new_vectorstore\n",
        "```\n",
        "\n",
        "### 2. **Multi-documents Support**\n",
        "\n",
        "```python\n",
        "# ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå\n",
        "def load_multiple_documents(file_paths):\n",
        "    all_documents = []\n",
        "    \n",
        "    for file_path in file_paths:\n",
        "        if file_path.endswith('.pdf'):\n",
        "            loader = PyPDFLoader(file_path)\n",
        "            documents = loader.load()\n",
        "            all_documents.extend(documents)\n",
        "        elif file_path.endswith('.txt'):\n",
        "            loader = TextLoader(file_path)\n",
        "            documents = loader.load()\n",
        "            all_documents.extend(documents)\n",
        "    \n",
        "    return all_documents\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á vector store ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
        "documents = load_multiple_documents(['doc1.pdf', 'doc2.pdf', 'doc3.txt'])\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "```\n",
        "\n",
        "### 3. **Enhanced Source Citations**\n",
        "\n",
        "```python\n",
        "# ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á\n",
        "def format_sources(sources):\n",
        "    formatted_sources = []\n",
        "    \n",
        "    for i, source in enumerate(sources, 1):\n",
        "        formatted_source = {\n",
        "            \"number\": i,\n",
        "            \"content\": source['content'][:300] + \"...\",\n",
        "            \"page\": source['metadata'].get('page', 'N/A'),\n",
        "            \"file\": source['metadata'].get('source', 'Unknown'),\n",
        "            \"relevance_score\": source.get('score', 'N/A')\n",
        "        }\n",
        "        formatted_sources.append(formatted_source)\n",
        "    \n",
        "    return formatted_sources\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô Streamlit\n",
        "for source in formatted_sources:\n",
        "    st.markdown(f\"**‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà {source['number']}:**\")\n",
        "    st.markdown(f\"üìÑ ‡πÑ‡∏ü‡∏•‡πå: {source['file']}\")\n",
        "    st.markdown(f\"üìÑ ‡∏´‡∏ô‡πâ‡∏≤: {source['page']}\")\n",
        "    st.markdown(f\"üìä ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {source['relevance_score']}\")\n",
        "    st.markdown(f\"üìù ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {source['content']}\")\n",
        "    st.markdown(\"---\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡∏õ‡∏¥‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
        "\n",
        "### ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏õ‡∏£‡∏±‡∏ö UI ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:\n",
        "\n",
        "#### 1. **‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á UI**\n",
        "- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ‡∏ò‡∏µ‡∏°\n",
        "- ‡πÄ‡∏û‡∏¥‡πà‡∏° animations\n",
        "- ‡∏õ‡∏£‡∏±‡∏ö layout\n",
        "- ‡πÄ‡∏û‡∏¥‡πà‡∏° emojis\n",
        "\n",
        "#### 2. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå**\n",
        "- Upload PDF ‡πÅ‡∏ö‡∏ö real-time\n",
        "- ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå\n",
        "- Export ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤\n",
        "- Search ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤\n",
        "\n",
        "#### 3. **‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á RAG**\n",
        "- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô embedding model\n",
        "- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á prompt template\n",
        "- ‡πÄ‡∏û‡∏¥‡πà‡∏° metadata filtering\n",
        "- ‡πÉ‡∏ä‡πâ chain type ‡∏≠‡∏∑‡πà‡∏ô\n",
        "\n",
        "#### 4. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤**\n",
        "- ‡∏õ‡∏£‡∏±‡∏ö chunk size\n",
        "- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô temperature\n",
        "- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å LLM model\n",
        "- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ k value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù ‡∏™‡∏£‡∏∏‡∏õ Workshop ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "\n",
        "### ‚úÖ Output ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏ö‡∏Ñ‡∏≠‡∏£‡πå‡∏™\n",
        "\n",
        "‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:\n",
        "\n",
        "1. **‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á RAG** üß†\n",
        "   - ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ç‡∏≠‡∏á LLM\n",
        "   - ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î RAG\n",
        "   - ‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏° RAG\n",
        "\n",
        "2. **‡πÉ‡∏ä‡πâ LangChain ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG pipeline** üîó\n",
        "   - Document Loading\n",
        "   - Text Splitting\n",
        "   - Embeddings\n",
        "   - Vector Store\n",
        "   - Retrieval\n",
        "   - LLM Integration\n",
        "\n",
        "3. **Deploy chatbot ‡∏û‡∏£‡πâ‡∏≠‡∏° UI ‡∏ö‡∏ô Streamlit** üé®\n",
        "   - ‡∏™‡∏£‡πâ‡∏≤‡∏á Chat Interface\n",
        "   - ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤\n",
        "   - ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á\n",
        "   - ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
        "\n",
        "4. **‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î** üöÄ\n",
        "   - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå\n",
        "   - Vector DB ‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å\n",
        "   - Advanced Features\n",
        "   - Production Deployment\n",
        "\n",
        "### üéì ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:\n",
        "\n",
        "1. `01_introduction_to_rag_langchain.ipynb` - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ RAG ‡πÅ‡∏•‡∏∞ LangChain\n",
        "2. `02_data_ingestion_vector_store.ipynb` - ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Vector Store\n",
        "3. `03_build_rag_pipeline.ipynb` - ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Pipeline\n",
        "4. `04_streamlit_ui.ipynb` - ‡∏™‡∏£‡πâ‡∏≤‡∏á Streamlit UI\n",
        "5. `05_wrapup_advanced_topics.ipynb` - Advanced Topics ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ\n",
        "6. `streamlit_app.py` - Streamlit Application ‡∏´‡∏•‡∏±‡∏Å\n",
        "\n",
        "### üèÜ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:\n",
        "\n",
        "- ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Chatbot ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå\n",
        "- ‚úÖ ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢ (LangChain, Groq, Streamlit)\n",
        "- ‚úÖ ‡∏°‡∏µ UI ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢\n",
        "- ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
        "- ‚úÖ ‡∏°‡∏µ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ ‡∏Ç‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ! ‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Chatbot ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß!**\n",
        "\n",
        "**üìö ‡∏ï‡πà‡∏≠‡πÑ‡∏õ: ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
