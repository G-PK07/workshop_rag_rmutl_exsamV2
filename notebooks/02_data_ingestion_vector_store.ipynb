{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìö Workshop: RAG + LangChain + Streamlit\n",
        "\n",
        "## ‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà 2: Data Ingestion & Vector Store (0:30 ‚Äì 1:30)\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
        "- ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (PDF, Text, Website)\n",
        "- ‡πÉ‡∏ä‡πâ LangChain DocumentLoader\n",
        "- ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ RecursiveCharacterTextSplitter\n",
        "- ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings (HuggingFaceEmbeddings)\n",
        "- ‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏á vector database (FAISS, Qdrant)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÑ ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Preparation)\n",
        "\n",
        "### ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö:\n",
        "\n",
        "1. **PDF Documents** üìÑ\n",
        "   - ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PDF ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ\n",
        "   - PDF ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ï‡∏≤‡∏£‡∏≤‡∏á\n",
        "   - PDF ‡∏ó‡∏µ‡πà‡∏™‡πÅ‡∏Å‡∏ô (OCR)\n",
        "\n",
        "2. **Text Files** üìù\n",
        "   - .txt files\n",
        "   - .md files\n",
        "   - .csv files\n",
        "\n",
        "3. **Web Content** üåê\n",
        "   - Web pages\n",
        "   - Wikipedia articles\n",
        "   - Blog posts\n",
        "\n",
        "4. **Structured Data** üìä\n",
        "   - JSON files\n",
        "   - XML files\n",
        "   - Database exports\n",
        "\n",
        "### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ:\n",
        "- `pdf/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô.pdf` - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô\n",
        "- `pdf/CV.pdf` - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully!\n",
            "üìÅ Current directory: /home/game/01_Projects/workshop_rag_rmutl/notebooks\n",
            "üìÑ PDF directory exists: True\n"
          ]
        }
      ],
      "source": [
        "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞ Import Libraries ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# ‡πÄ‡∏û‡∏¥‡πà‡∏° path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö import modules\n",
        "sys.path.append('..')\n",
        "\n",
        "# Import LangChain components\n",
        "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS, Qdrant\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Import utilities\n",
        "from dotenv import load_dotenv\n",
        "import logging\n",
        "\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
        "print(f\"üìÑ PDF directory exists: {os.path.exists('../pdf')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì• Document Loader\n",
        "\n",
        "### LangChain Document Loaders\n",
        "\n",
        "LangChain ‡∏°‡∏µ Document Loaders ‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó:\n",
        "\n",
        "1. **PyPDFLoader** - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PDF files\n",
        "2. **TextLoader** - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö text files\n",
        "3. **CSVLoader** - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CSV files\n",
        "4. **WebBaseLoader** - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö web content\n",
        "5. **DirectoryLoader** - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "\n",
        "### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ../pdf/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô.pdf\n",
            "üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤: 6\n",
            "üìù ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: 9363\n",
            "\n",
            "üìñ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å:\n",
            "--------------------------------------------------\n",
            "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô \n",
            "‡∏ô‡πà‡∏≤‡∏ô ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏≤‡∏á‡∏ó‡∏¥‡∏®‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á\n",
            "‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ß‡∏µ‡∏¢‡∏á‡∏ß‡∏£‡∏ô‡∏Ñ‡∏£ (‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏û‡∏•‡∏±‡∏ß) ‡πÄ‡∏ß‡∏µ‡∏¢‡∏á‡∏®‡∏µ‡∏£‡∏©‡∏∞‡πÄ‡∏Å‡∏© (‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏á‡∏±‡πà‡∏ß) ‡πÄ‡∏ß‡∏µ‡∏¢‡∏á‡∏†‡∏π‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏ä‡πà\n",
            "‡πÅ‡∏´‡πâ‡∏á ‡∏≠‡∏µ‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ï‡πâ‡∏ô‡∏ô‡πâ‡∏≥‡∏Ç‡∏≠‡∏á‡πÅ‡∏°‡πà‡∏ô‡πâ‡∏≥‡∏ô‡πà‡∏≤‡∏ô \n",
            "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå  ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏Å‡πà‡∏¢‡∏≤‡∏ß‡∏ô‡∏≤‡∏ô ‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ô‡∏û‡∏á‡∏®‡∏≤‡∏ß‡∏î‡∏≤‡∏£‡∏ß‡πà‡∏≤ ‡∏ô‡∏±‡∏ô‡∏ó\n",
            "‡∏ö‡∏∏‡∏£‡∏µ ‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏Ñ‡∏£‡∏£‡∏±‡∏ê‡πÄ‡∏•‡πá‡∏Å  ‡πÜ ‡∏Å‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏£‡∏≤‡∏ß‡∏Å‡∏•‡∏≤‡∏á‡∏û‡∏∏‡∏ó‡∏ò‡∏®‡∏ï‡∏ß‡∏£‡∏£‡∏©‡∏ó‡∏µ‡πà  18 ‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏ö‡∏•‡∏∏‡πà‡∏°\n",
            "‡πÅ‡∏°‡πà‡∏ô‡πâ‡∏≥‡∏ô‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡πà‡∏ô‡πâ‡∏≥‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏´‡∏∏‡∏ö‡πÄ‡∏Ç‡∏≤‡∏ó‡∏≤‡∏á‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ \n",
            "‡∏™‡∏°‡∏±‡∏¢‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏•‡πà‡∏≤‡∏á-‡∏ß‡∏£‡∏ô‡∏Ñ‡∏£ \n",
            "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ô‡πà...\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ‡πÇ‡∏´‡∏•‡∏î PDF Document\n",
        "def load_pdf_document(file_path):\n",
        "    \"\"\"‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ PDF ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\"\"\"\n",
        "    try:\n",
        "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á PDF Loader\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        \n",
        "        # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
        "        documents = loader.load()\n",
        "        \n",
        "        print(f\"üìÑ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {file_path}\")\n",
        "        print(f\"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤: {len(documents)}\")\n",
        "        print(f\"üìù ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {sum(len(doc.page_content) for doc in documents)}\")\n",
        "        \n",
        "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å\n",
        "        if documents:\n",
        "            print(f\"\\nüìñ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å:\")\n",
        "            print(\"-\" * 50)\n",
        "            print(documents[0].page_content[:500] + \"...\")\n",
        "            print(\"-\" * 50)\n",
        "        \n",
        "        return documents\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}\")\n",
        "        return []\n",
        "\n",
        "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏´‡∏•‡∏î PDF\n",
        "pdf_path = \"../pdf/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô.pdf\"\n",
        "if os.path.exists(pdf_path):\n",
        "    documents = load_pdf_document(pdf_path)\n",
        "else:\n",
        "    print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {pdf_path}\")\n",
        "    documents = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÇÔ∏è Text Splitter\n",
        "\n",
        "### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£?\n",
        "\n",
        "1. **Context Window Limit**: LLM ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß\n",
        "2. **Semantic Search**: ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô chunks ‡πÄ‡∏•‡πá‡∏Å‡πÜ\n",
        "3. **Memory Efficiency**: ‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•\n",
        "\n",
        "### RecursiveCharacterTextSplitter\n",
        "\n",
        "**RecursiveCharacterTextSplitter** ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏Ñ‡∏±‡πà‡∏ô:\n",
        "\n",
        "1. `\\n\\n` (‡∏¢‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤)\n",
        "2. `\\n` (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà)\n",
        "3. ` ` (‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á)\n",
        "4. `\"\"` (‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)\n",
        "\n",
        "### ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:\n",
        "- `chunk_size`: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ chunk (‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)\n",
        "- `chunk_overlap`: ‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÇÔ∏è ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô chunks\n",
            "üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks: 13\n",
            "üìè ‡∏Ç‡∏ô‡∏≤‡∏î chunk: 1000 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
            "üîÑ ‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô: 200 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
            "\n",
            "üìñ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á chunks:\n",
            "--------------------------------------------------\n",
            "Chunk 1:\n",
            "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: 989 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
            "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô \n",
            "‡∏ô‡πà‡∏≤‡∏ô ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏≤‡∏á‡∏ó‡∏¥‡∏®‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á\n",
            "‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏≠‡∏î‡∏µ‡∏ï ‡πÄ‡∏ä‡πà‡∏ô ‡πÄ‡∏ß‡∏µ‡∏¢‡∏á‡∏ß‡∏£‡∏ô‡∏Ñ‡∏£ (‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏û‡∏•‡∏±‡∏ß) ‡πÄ‡∏ß‡∏µ‡∏¢‡∏á‡∏®‡∏µ‡∏£‡∏©‡∏∞‡πÄ‡∏Å‡∏© (‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏á‡∏±‡πà‡∏ß) ‡πÄ‡∏ß‡∏µ‡∏¢‡∏á‡∏†‡∏π‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡πÅ‡∏ä‡πà\n",
            "‡πÅ‡∏´‡πâ‡∏á ‡∏≠‡∏µ‡∏Å‡∏ó‡∏±‡πâ‡∏á...\n",
            "------------------------------\n",
            "Chunk 2:\n",
            "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: 944 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
            "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡πÄ‡∏™‡∏µ‡πâ‡∏¢‡∏ß ‡∏ö‡πâ‡∏≤‡∏ô‡∏ó‡∏∏‡πà‡∏á‡∏Ü‡πâ‡∏≠‡∏á  ‡∏ö‡πâ‡∏≤‡∏ô‡∏•‡∏≠‡∏°‡∏Å‡∏•‡∏≤‡∏á  ‡∏ï‡∏≥‡∏ö‡∏•‡∏¢‡∏° ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏ó‡πà‡∏≤‡∏ß‡∏±‡∏á‡∏ú‡∏≤ ) ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏ä‡∏∏‡∏°‡∏ä‡∏ô‡πÉ‡∏ô\n",
            "‡∏™‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏π‡∏ô‡πâ‡∏≥  ‡∏Ñ‡∏±‡∏ô‡∏î‡∏¥‡∏ô ‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà  ‡πÄ‡∏´‡πá‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏Ç‡πâ‡∏≤‡∏á‡∏û‡∏£‡∏∞‡∏ò‡∏≤‡∏ï‡∏∏\n",
            "‡∏à‡∏≠‡∏°‡∏û‡∏£‡∏¥‡∏Å‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏™‡∏µ‡πâ‡∏¢‡∏ß ‡∏°‡∏µ‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á...\n",
            "------------------------------\n",
            "Chunk 3:\n",
            "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: 261 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
            "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡∏Ñ‡∏£‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ó‡∏ô ‡∏à‡∏∂‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏ô‡∏≤‡∏≠‡∏≥‡∏°‡∏≤‡∏ï‡∏¢‡πå‡πÑ‡∏õ‡πÄ‡∏ä‡∏¥‡∏ç ‡πÄ‡∏à‡πâ‡∏≤‡πÄ‡∏Å‡πâ‡∏≤‡πÄ‡∏ñ‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏Å‡∏£‡∏á‡πÉ‡∏à‡∏õ‡∏π‡πà‡∏à‡∏∂‡∏á‡∏¢‡∏≠‡∏°‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞\n",
            "‡∏°‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏ä‡∏≤‡∏¢‡∏≤‡∏Ñ‡∏∑‡∏≠‡∏ô‡∏≤‡∏á‡∏û‡∏ç‡∏≤‡πÅ‡∏°‡πà‡∏ó‡πâ‡∏≤‡∏ß‡∏Ñ‡∏≥‡∏õ‡∏¥‡∏ô‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏õ‡∏±‡∏ß‡πÅ‡∏ó‡∏ô ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ç‡∏≤‡∏†‡∏π‡∏Ñ‡∏≤‡∏ñ‡∏∂‡∏á‡πÅ‡∏Å‡πà‡∏û‡∏¥‡∏£‡∏≤‡∏•‡∏±‡∏¢ ‡πÄ‡∏à‡πâ‡∏≤\n",
            "‡πÄ‡∏Å‡πâ‡∏≤‡πÄ‡∏ñ‡∏∑‡πà‡∏≠‡∏ô‡∏à‡∏∂‡∏á‡∏Ñ‡∏£‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ó...\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô chunks\n",
        "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
        "    \"\"\"‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô chunks\"\"\"\n",
        "    try:\n",
        "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Text Splitter\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap,\n",
        "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        "        )\n",
        "        \n",
        "        # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
        "        chunks = text_splitter.split_documents(documents)\n",
        "        \n",
        "        print(f\"‚úÇÔ∏è ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô chunks\")\n",
        "        print(f\"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô chunks: {len(chunks)}\")\n",
        "        print(f\"üìè ‡∏Ç‡∏ô‡∏≤‡∏î chunk: {chunk_size} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\")\n",
        "        print(f\"üîÑ ‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô: {chunk_overlap} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\")\n",
        "        \n",
        "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á chunks\n",
        "        print(f\"\\nüìñ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á chunks:\")\n",
        "        print(\"-\" * 50)\n",
        "        for i, chunk in enumerate(chunks[:3]):  # ‡πÅ‡∏™‡∏î‡∏á 3 chunks ‡πÅ‡∏£‡∏Å\n",
        "            print(f\"Chunk {i+1}:\")\n",
        "            print(f\"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {len(chunk.page_content)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\")\n",
        "            print(f\"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {chunk.page_content[:200]}...\")\n",
        "            print(\"-\" * 30)\n",
        "        \n",
        "        return chunks\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}\")\n",
        "        return []\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\n",
        "if documents:\n",
        "    chunks = split_documents(documents, chunk_size=1000, chunk_overlap=200)\n",
        "else:\n",
        "    print(\"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÉ‡∏´‡πâ‡πÅ‡∏ö‡πà‡∏á\")\n",
        "    chunks = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî¢ Embeddings\n",
        "\n",
        "### Embeddings ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
        "\n",
        "**Embeddings** ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (vectors) ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ\n",
        "\n",
        "### ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á Embeddings:\n",
        "\n",
        "1. **OpenAI Embeddings** - ‡πÉ‡∏ä‡πâ OpenAI API (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢)\n",
        "2. **HuggingFace Embeddings** - ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å HuggingFace (‡∏ü‡∏£‡∏µ)\n",
        "3. **Sentence Transformers** - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö embeddings\n",
        "\n",
        "### HuggingFace Embeddings ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:\n",
        "\n",
        "- `all-MiniLM-L6-v2` - ‡∏Ç‡∏ô‡∏≤‡∏î‡πÄ‡∏•‡πá‡∏Å, ‡πÄ‡∏£‡πá‡∏ß (384 dimensions)\n",
        "- `all-mpnet-base-v2` - ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ (768 dimensions)\n",
        "- `paraphrase-multilingual-MiniLM-L12-v2` - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0\n",
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¢ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings Model: all-MiniLM-L6-v2\n",
            "‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\n",
            "üìè Vector dimensions: 384\n",
            "üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö embedding: 384 dimensions\n"
          ]
        }
      ],
      "source": [
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings\n",
        "def create_embeddings(model_name=\"all-MiniLM-L6-v2\"):\n",
        "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings model\"\"\"\n",
        "    try:\n",
        "        print(f\"üî¢ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings Model: {model_name}\")\n",
        "        \n",
        "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á HuggingFace Embeddings\n",
        "        embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=model_name,\n",
        "            cache_folder=\"../model_cache\"  # ‡πÄ‡∏Å‡πá‡∏ö cache ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå model_cache\n",
        "        )\n",
        "        \n",
        "        print(f\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "        print(f\"üìè Vector dimensions: {embeddings.client.get_sentence_embedding_dimension()}\")\n",
        "        \n",
        "        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö embeddings\n",
        "        test_text = \"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?\"\n",
        "        test_embedding = embeddings.embed_query(test_text)\n",
        "        print(f\"üß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö embedding: {len(test_embedding)} dimensions\")\n",
        "        \n",
        "        return embeddings\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}\")\n",
        "        return None\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings\n",
        "embeddings = create_embeddings(\"all-MiniLM-L6-v2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üóÑÔ∏è Vector Store\n",
        "\n",
        "### Vector Store ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?\n",
        "\n",
        "**Vector Store** ‡∏Ñ‡∏∑‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏•‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ vectors (embeddings) ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û\n",
        "\n",
        "### ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á Vector Store:\n",
        "\n",
        "1. **FAISS** (Facebook AI Similarity Search)\n",
        "   - ‚úÖ ‡πÄ‡∏£‡πá‡∏ß, ‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡πâ‡∏≠‡∏¢\n",
        "   - ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö similarity\n",
        "   - ‚ùå ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ (‡πÑ‡∏°‡πà persistent)\n",
        "\n",
        "2. **Qdrant**\n",
        "   - ‚úÖ Persistent storage\n",
        "   - ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö metadata filtering\n",
        "   - ‚úÖ API ‡∏ó‡∏µ‡πà‡∏î‡∏µ\n",
        "   - ‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á server ‡πÅ‡∏¢‡∏Å\n",
        "\n",
        "3. **Chroma**\n",
        "   - ‚úÖ ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
        "   - ‚úÖ Persistent storage\n",
        "   - ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóÑÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS Vector Store...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS Vector Store ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\n",
            "üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô documents: 13\n",
            "\n",
            "üîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?\n",
            "üìã ‡∏û‡∏ö 3 documents ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:\n",
            "\n",
            "Document 1:\n",
            "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: 246 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
            "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡∏™‡∏°‡∏±‡∏¢‡∏Å‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏ï‡∏ô‡πÇ‡∏Å‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡πå ‡∏ô‡∏Ñ‡∏£‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏ê‡∏≤‡∏ô‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏±‡∏ß‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏£‡∏≤‡∏ä ‡πÄ‡∏à‡πâ‡∏≤‡∏ú‡∏π‡πâ‡∏Ñ‡∏£‡∏≠‡∏á‡∏ô‡∏Ñ‡∏£‡∏ô‡πà‡∏≤‡∏ô‡πÉ‡∏ô‡∏ä‡∏±‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á\n",
            "‡∏ó‡∏∏‡∏Å‡∏≠‡∏á‡∏Ñ‡πå‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏≤‡∏ä‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏ò‡∏£‡∏£‡∏° ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏ï‡∏¢‡πå ‡∏à‡∏á‡∏£‡∏±‡∏Å‡∏†‡∏±‡∏Å‡∏î‡∏µ‡∏ï‡πà‡∏≠\n",
            "‡∏û‡∏£‡∏∞‡∏°‡∏´‡∏≤‡∏Å‡∏©‡∏±‡∏ï‡∏£‡∏¥‡∏¢‡πå‡πÅ‡∏´‡πà‡∏á‡∏£‡∏≤‡∏ä‡∏ß‡∏á‡∏®‡πå‡∏à‡∏±‡∏Å‡∏£‡∏µ ‡πÑ‡∏î‡πâ‡∏ä...\n",
            "Metadata: {'producer': 'Microsoft¬Æ Word for Microsoft 365', 'creator': 'Microsoft¬Æ Word for Microsoft 365', 'creationdate': '2025-02-20T03:12:14+07:00', 'author': 'Jeerasak Ananta', 'moddate': '2025-02-20T03:12:14+07:00', 'source': '../pdf/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}\n",
            "\n",
            "Document 2:\n",
            "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: 261 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
            "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡∏Ñ‡∏£‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ó‡∏ô ‡∏à‡∏∂‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏ô‡∏≤‡∏≠‡∏≥‡∏°‡∏≤‡∏ï‡∏¢‡πå‡πÑ‡∏õ‡πÄ‡∏ä‡∏¥‡∏ç ‡πÄ‡∏à‡πâ‡∏≤‡πÄ‡∏Å‡πâ‡∏≤‡πÄ‡∏ñ‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏Å‡∏£‡∏á‡πÉ‡∏à‡∏õ‡∏π‡πà‡∏à‡∏∂‡∏á‡∏¢‡∏≠‡∏°‡πÑ‡∏õ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞\n",
            "‡∏°‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏ä‡∏≤‡∏¢‡∏≤‡∏Ñ‡∏∑‡∏≠‡∏ô‡∏≤‡∏á‡∏û‡∏ç‡∏≤‡πÅ‡∏°‡πà‡∏ó‡πâ‡∏≤‡∏ß‡∏Ñ‡∏≥‡∏õ‡∏¥‡∏ô‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏õ‡∏±‡∏ß‡πÅ‡∏ó‡∏ô ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ç‡∏≤‡∏†‡∏π‡∏Ñ‡∏≤‡∏ñ‡∏∂‡∏á‡πÅ‡∏Å‡πà‡∏û‡∏¥‡∏£‡∏≤‡∏•‡∏±‡∏¢ ‡πÄ‡∏à‡πâ‡∏≤\n",
            "‡πÄ‡∏Å‡πâ‡∏≤‡πÄ‡∏ñ‡∏∑‡πà‡∏≠‡∏ô‡∏à‡∏∂‡∏á‡∏Ñ‡∏£‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ó...\n",
            "Metadata: {'producer': 'Microsoft¬Æ Word for Microsoft 365', 'creator': 'Microsoft¬Æ Word for Microsoft 365', 'creationdate': '2025-02-20T03:12:14+07:00', 'author': 'Jeerasak Ananta', 'moddate': '2025-02-20T03:12:14+07:00', 'source': '../pdf/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
            "\n",
            "Document 3:\n",
            "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: 957 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\n",
            "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: ‡∏™‡∏°‡∏±‡∏¢‡∏•‡πâ‡∏≤‡∏ô‡∏ô‡∏≤ \n",
            "‡πÉ‡∏ô‡∏õ‡∏µ ‡∏û.‡∏®. 1993 ‡∏û‡∏£‡∏∞‡πÄ‡∏à‡πâ‡∏≤‡∏ï‡∏¥‡πÇ‡∏•‡∏Å‡∏£‡∏≤‡∏ä‡∏Å‡∏©‡∏±‡∏ï‡∏£‡∏¥‡∏¢‡πå‡∏ô‡∏Ñ‡∏£‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏à‡∏∞‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏≠‡∏á\n",
            "‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ô‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏Å‡∏•‡∏∑‡∏≠‡∏ö‡πà‡∏≠‡∏°‡∏≤‡∏á  (‡πÄ‡∏Ç‡∏ï‡∏ï‡∏≥‡∏ö‡∏•‡∏ö‡πà‡∏≠‡πÄ‡∏Å‡∏•‡∏∑‡∏≠‡πÉ‡∏ï‡πâ  ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏ö‡πà‡∏≠‡πÄ‡∏Å‡∏•‡∏∑‡∏≠‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô ) ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏∏‡∏î‡∏°\n",
            "‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡πÑ‡∏î‡πâ‡∏¢‡∏≤‡∏Å‡∏ó‡∏≤‡∏á‡∏†‡∏≤...\n",
            "Metadata: {'producer': 'Microsoft¬Æ Word for Microsoft 365', 'creator': 'Microsoft¬Æ Word for Microsoft 365', 'creationdate': '2025-02-20T03:12:14+07:00', 'author': 'Jeerasak Ananta', 'moddate': '2025-02-20T03:12:14+07:00', 'source': '../pdf/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}\n"
          ]
        }
      ],
      "source": [
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store (FAISS)\n",
        "def create_faiss_vectorstore(chunks, embeddings):\n",
        "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS Vector Store\"\"\"\n",
        "    try:\n",
        "        print(\"üóÑÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS Vector Store...\")\n",
        "        \n",
        "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS vector store\n",
        "        vectorstore = FAISS.from_documents(\n",
        "            documents=chunks,\n",
        "            embedding=embeddings\n",
        "        )\n",
        "        \n",
        "        print(f\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS Vector Store ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "        print(f\"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô documents: {vectorstore.index.ntotal}\")\n",
        "        \n",
        "        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤\n",
        "        test_query = \"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?\"\n",
        "        print(f\"\\nüîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {test_query}\")\n",
        "        \n",
        "        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ documents ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á\n",
        "        similar_docs = vectorstore.similarity_search(test_query, k=3)\n",
        "        \n",
        "        print(f\"üìã ‡∏û‡∏ö {len(similar_docs)} documents ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:\")\n",
        "        for i, doc in enumerate(similar_docs, 1):\n",
        "            print(f\"\\nDocument {i}:\")\n",
        "            print(f\"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß: {len(doc.page_content)} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£\")\n",
        "            print(f\"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {doc.page_content[:200]}...\")\n",
        "            print(f\"Metadata: {doc.metadata}\")\n",
        "        \n",
        "        return vectorstore\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}\")\n",
        "        return None\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store\n",
        "if chunks and embeddings:\n",
        "    vectorstore = create_faiss_vectorstore(chunks, embeddings)\n",
        "else:\n",
        "    print(\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store ‡πÑ‡∏î‡πâ - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö chunks ‡πÅ‡∏•‡∏∞ embeddings\")\n",
        "    vectorstore = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Vector Stores\n",
        "\n",
        "### ‡∏ó‡∏î‡∏™‡∏≠‡∏ö FAISS vs Qdrant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóÑÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant Vector Store...\n",
            "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant Vector Store: Failed to parse: :memory:\n",
            "üí° ‡πÉ‡∏ä‡πâ FAISS ‡πÅ‡∏ó‡∏ô\n"
          ]
        }
      ],
      "source": [
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant Vector Store (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Qdrant server)\n",
        "def create_qdrant_vectorstore(chunks, embeddings):\n",
        "    \"\"\"‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant Vector Store\"\"\"\n",
        "    try:\n",
        "        print(\"üóÑÔ∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant Vector Store...\")\n",
        "        \n",
        "        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant vector store\n",
        "        vectorstore = Qdrant.from_documents(\n",
        "            documents=chunks,\n",
        "            embedding=embeddings,\n",
        "            collection_name=\"documents\",\n",
        "            url=\":memory:\",  # ‡πÉ‡∏ä‡πâ in-memory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö demo\n",
        "            prefer_grpc=True\n",
        "        )\n",
        "        \n",
        "        print(f\"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant Vector Store ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "        \n",
        "        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤\n",
        "        test_query = \"‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡πà‡∏≤‡∏ô‡∏°‡∏µ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?\"\n",
        "        print(f\"\\nüîç ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {test_query}\")\n",
        "        \n",
        "        similar_docs = vectorstore.similarity_search(test_query, k=2)\n",
        "        \n",
        "        print(f\"üìã ‡∏û‡∏ö {len(similar_docs)} documents ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á:\")\n",
        "        for i, doc in enumerate(similar_docs, 1):\n",
        "            print(f\"\\nDocument {i}:\")\n",
        "            print(f\"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {doc.page_content[:150]}...\")\n",
        "        \n",
        "        return vectorstore\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant Vector Store: {e}\")\n",
        "        print(\"üí° ‡πÉ‡∏ä‡πâ FAISS ‡πÅ‡∏ó‡∏ô\")\n",
        "        return None\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Qdrant Vector Store (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ)\n",
        "if chunks and embeddings:\n",
        "    qdrant_vectorstore = create_qdrant_vectorstore(chunks, embeddings)\n",
        "else:\n",
        "    qdrant_vectorstore = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store\n",
        "\n",
        "### ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å FAISS Vector Store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store ‡πÑ‡∏õ‡∏ó‡∏µ‡πà: ../vectorstore\n",
            "‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\n"
          ]
        }
      ],
      "source": [
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store\n",
        "def save_vectorstore(vectorstore, save_path=\"../vectorstore\"):\n",
        "    \"\"\"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store\"\"\"\n",
        "    try:\n",
        "        if vectorstore:\n",
        "            print(f\"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store ‡πÑ‡∏õ‡∏ó‡∏µ‡πà: {save_path}\")\n",
        "            vectorstore.save_local(save_path)\n",
        "            print(\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ Vector Store ‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {e}\")\n",
        "        return False\n",
        "\n",
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store\n",
        "if vectorstore:\n",
        "    save_success = save_vectorstore(vectorstore)\n",
        "else:\n",
        "    print(\"‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ Vector Store ‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù ‡∏™‡∏£‡∏∏‡∏õ‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà 2\n",
        "\n",
        "### ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:\n",
        "\n",
        "1. **Document Loading** üìÑ\n",
        "   - ‡πÉ‡∏ä‡πâ PyPDFLoader ‡πÇ‡∏´‡∏•‡∏î PDF\n",
        "   - ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤, ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)\n",
        "\n",
        "2. **Text Splitting** ‚úÇÔ∏è\n",
        "   - ‡πÉ‡∏ä‡πâ RecursiveCharacterTextSplitter\n",
        "   - ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô chunks ‡∏û‡∏£‡πâ‡∏≠‡∏° overlap\n",
        "\n",
        "3. **Embeddings** üî¢\n",
        "   - ‡πÉ‡∏ä‡πâ HuggingFaceEmbeddings\n",
        "   - ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô vectors\n",
        "\n",
        "4. **Vector Store** üóÑÔ∏è\n",
        "   - ‡∏™‡∏£‡πâ‡∏≤‡∏á FAISS Vector Store\n",
        "   - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ similarity search\n",
        "   - ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store\n",
        "\n",
        "### Pipeline ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô:\n",
        "```\n",
        "PDF ‚Üí Document Loader ‚Üí Text Splitter ‚Üí Embeddings ‚Üí Vector Store\n",
        "```\n",
        "\n",
        "### ‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà 3:\n",
        "‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Pipeline ‡πÅ‡∏•‡∏∞‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö LLM\n",
        "\n",
        "---\n",
        "\n",
        "**‚è∞ ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: 60 ‡∏ô‡∏≤‡∏ó‡∏µ**\n",
        "**üìö ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≠‡πÑ‡∏õ: `03_build_rag_pipeline.ipynb`**\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
